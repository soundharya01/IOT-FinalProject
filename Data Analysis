from flask import Flask, request, jsonify
from influxdb_client import InfluxDBClient, Point, WriteOptions
from influxdb_client.client.write_api import SYNCHRONOUS
import paho.mqtt.client as mqtt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

app = Flask(__name__)

# InfluxDB Credentials
INFLUXDB_URL = 'https://us-west-2-1.aws.cloud2.influxdata.com'
TOKEN = 'your_influxdb_token'
ORG = 'your_organization_id'
BUCKET = 'your_bucket_id'

# MQTT Broker Information
MQTT_BROKER_IP = '192.168.26.66'
MQTT_TOPIC = '@shadow/data/update'

# Initialize InfluxDB client
influxdb_client = InfluxDBClient(url=INFLUXDB_URL, token=TOKEN)

# Initialize MQTT client
mqtt_client = mqtt.Client()


# Default Route
@app.route('/')
def hello():
    return jsonify({"Status": "My API server is running"})


# Route for handling GET requests
@app.route('/get_data', methods=['GET'])
def get_data():
    # Fetch data from InfluxDB
    query = f'from(bucket: "{BUCKET}") |> range(start: -1h)'
    result = influxdb_client.query_api().query(query, org=ORG)
    data = result.to_dataframe()
    return jsonify(data.to_dict())


# Route for handling POST requests
@app.route('/add_data', methods=['POST'])
def add_data():
    req_data = request.get_json()
    if req_data:
        # Write data to InfluxDB
        write_api = influxdb_client.write_api(
            write_options=WriteOptions(batch_size=500, flush_interval=10_000, jitter_interval=2_000,
                                       retry_interval=5_000))
        point = Point("measurement").field("value", req_data["value"])
        write_api.write(BUCKET, ORG, point)

        # Train a machine learning model
        train_model()

        # Make predictions on the new data
        prediction = predict(req_data)

        # Publish prediction to MQTT topic
        mqtt_client.connect(MQTT_BROKER_IP)
        mqtt_client.publish(MQTT_TOPIC, prediction)
        mqtt_client.disconnect()

        return jsonify({"message": "Data added successfully", "prediction": prediction})
    else:
        return jsonify({"error": "No data provided"}), 400


def train_model():
    # Load data from InfluxDB for training
    query = f'from(bucket: "{BUCKET}") |> range(start: -1d)'
    result = influxdb_client.query_api().query(query, org=ORG)
    data = result.to_dataframe()

    # Perform data preprocessing and feature engineering as needed
    # For example, convert timestamp to datetime, handle missing values, encode categorical variables, etc.

    # Split data into features and target variable
    X = data.drop(columns=["target_variable"])
    y = data["target_variable"]

    # Split data into train and test sets
    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train a machine learning model (e.g., RandomForestClassifier)
    model = RandomForestClassifier()
    model.fit(X_train, y_train)

    # Optionally, save the trained model for future use


def predict(new_data):
    # Load the trained model (if not already loaded)
    # Predict the target variable for the new data
    # Return the prediction
    return "prediction"


if __name__ == '__main__':
    app.run()
